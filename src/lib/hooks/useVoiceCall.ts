'use client'

import { socket } from '@/src/lib/socket'
import {
	PeerState,
	VoiceTransportOptions,
} from '@/src/server/socket/schemas/call.schema'
import * as mediasoupClient from 'mediasoup-client'
import { RtpCapabilities } from 'mediasoup/types'
import { useEffect, useRef, useState } from 'react'

type CallType = 'only-voice' | 'only-camera' | 'only-screen'
type CallControll = {
	startCalling: (callId: string) => Promise<void>
	stopCalling: () => void
	getJoinList: () => Promise<PeerState[]>
}
type VoiceControl = { toggleMic: () => void; isMicOn: boolean }
type CameraControl = { toggleCamera: () => Promise<void>; isCameraOn: boolean }
type ScreenControl = { toggleScreen: () => Promise<void>; isScreenOn: boolean }

export function useVoiceCall(): CallControll &
	VoiceControl &
	CameraControl &
	ScreenControl
export function useVoiceCall(
	callType: 'only-voice'
): CallControll & VoiceControl
export function useVoiceCall(
	callType: 'only-camera'
): CallControll & CameraControl
export function useVoiceCall(
	callType: 'only-screen'
): CallControll & ScreenControl
export function useVoiceCall(
	callType?: CallType
):
	| (CallControll & VoiceControl & CameraControl & ScreenControl)
	| (CallControll & VoiceControl)
	| (CallControll & CameraControl)
	| (CallControll & ScreenControl)

export function useVoiceCall(
	callType?: CallType
):
	| (CallControll & VoiceControl & CameraControl & ScreenControl)
	| (CallControll & VoiceControl)
	| (CallControll & CameraControl)
	| (CallControll & ScreenControl) {
	const [callId, setCallId] = useState<string | null>(null)

	const [isMicOn, setIsMicOn] = useState(true)
	const [isCameraOn, setIsCameraOn] = useState(false)
	const [isScreenOn, setIsScreenOn] = useState(false)

	const [sendTransport, setSendTransport] =
		useState<mediasoupClient.types.Transport | null>(null)
	const [recvTransport, setRecvTransport] =
		useState<mediasoupClient.types.Transport | null>(null)
	const [voiceProducer, setVoiceProducer] =
		useState<mediasoupClient.types.Producer | null>(null)
	const [cameraProducer, setCameraProducer] =
		useState<mediasoupClient.types.Producer | null>(null)
	const [screenProducer, setScreenProducer] =
		useState<mediasoupClient.types.Producer | null>(null)
	const [localStream, setLocalStream] = useState<MediaStream | null>(null)

	const deviceRef = useRef<mediasoupClient.Device>(null)
	const consumersRef = useRef<mediasoupClient.types.Consumer[]>([])
	const audioElementsRef = useRef<HTMLAudioElement[]>([])
	const videoElementsRef = useRef<HTMLVideoElement[]>([])

	async function initDevice() {
		let device = deviceRef.current ?? new mediasoupClient.Device()

		if (!device.loaded) {
			const routerRtpCapabilities = await new Promise<RtpCapabilities>(
				(resolve) => {
					socket.emit('call_getRouterRtpCapabilities', (res) => resolve(res))
				}
			)

			await device.load({ routerRtpCapabilities })
		}

		deviceRef.current = device
	}

	useEffect(() => {
		initDevice()
	}, [])

	function toggleMic() {
		if (!voiceProducer) {
			console.warn('âš ï¸ producerê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
			return
		}

		setIsMicOn((prev) => {
			if (prev) {
				voiceProducer.pause()
				console.log('ğŸ”‡ ë§ˆì´í¬ ìŒì†Œê±°ë¨')
			} else {
				voiceProducer.resume()
				console.log('ğŸ™ï¸ ë§ˆì´í¬ ìŒì†Œê±° í•´ì œë¨')
			}
			return !prev
		})
	}

	async function toggleCamera() {
		if (!cameraProducer) {
			const stream = await navigator.mediaDevices.getUserMedia({ video: true })
			const track = stream.getVideoTracks()[0]

			if (!sendTransport) {
				console.log('ë¨¼ì € ë°©ì— ì…ì¥í•´ì£¼ì„¸ìš”')
				return
			}

			const newCameraProducer = await sendTransport.produce({ track })

			const video = document.createElement('video')
			video.srcObject = new MediaStream([track])
			video.autoplay = true
			video.playsInline = true
			video.muted = true // ë³¸ì¸ ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸° ì‹œ ë¬´ì¡°ê±´ muted í•„ìš”

			// ì—¬ê¸° ë°”ê¿”
			document.body.appendChild(video)
			videoElementsRef.current.push(video)

			setCameraProducer(newCameraProducer)
			setIsCameraOn(true)

			console.log('ğŸ“· ì¹´ë©”ë¼ ì¼œì§')
		} else {
			setIsCameraOn((prev) => {
				if (prev) {
					cameraProducer.pause()
					console.log('ğŸ“· ì¹´ë©”ë¼ êº¼ì§')
				} else {
					cameraProducer.resume()
					console.log('ğŸ“· ì¹´ë©”ë¼ ë‹¤ì‹œ ì¼œì§')
				}
				return !prev
			})
		}
	}

	async function toggleScreen() {
		if (!screenProducer) {
			const stream = await navigator.mediaDevices.getDisplayMedia({
				video: true,
			})
			const track = stream.getVideoTracks()[0]

			if (!sendTransport) {
				console.log('ë¨¼ì € ë°©ì— ì…ì¥í•´ì£¼ì„¸ìš”')
				return
			}

			const newScreenProducer = await sendTransport.produce({ track })

			const video = document.createElement('video')
			video.srcObject = new MediaStream([track])
			video.autoplay = true
			video.playsInline = true
			video.muted = true // ë³¸ì¸ ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸° ì‹œ ë¬´ì¡°ê±´ muted í•„ìš”

			// ì—¬ê¸° ë°”ê¿”
			document.body.appendChild(video)
			videoElementsRef.current.push(video)

			track.onended = () => {
				setIsScreenOn(false)
				newScreenProducer.close()
				setScreenProducer(null)
			}

			setScreenProducer(newScreenProducer)
			setIsCameraOn(true)
			console.log('ğŸ“· í™”ë©´ê³µìœ  ì¼œì§')
		} else {
			setIsScreenOn((prev) => {
				if (prev) {
					screenProducer.pause()
					console.log('ğŸ“· í™”ë©´ê³µìœ  êº¼ì§')
				} else {
					screenProducer.resume()
					console.log('ğŸ“· í™”ë©´ê³µìœ  ë‹¤ì‹œ ì¼œì§')
				}
				return !prev
			})
		}
	}

	async function startCalling(callId: string) {
		if (!deviceRef.current || !deviceRef.current.loaded) {
			await initDevice()
			return
		}
		// [3] ì„œë²„ì— ì†¡ì‹ ìš© transport ìš”ì²­
		const transportInfo = await new Promise<
			| VoiceTransportOptions
			| {
					error: string
			  }
		>((resolve) => {
			socket.emit('call_createTransport', 'send', (res) => resolve(res))
		})

		if ('error' in transportInfo) {
			console.error('âŒ Transport ìƒì„± ì‹¤íŒ¨:', transportInfo.error)
			return
		}

		// [4] í´ë¼ì´ì–¸íŠ¸ ì¸¡ sendTransport ìƒì„±
		const newSendTransport = deviceRef.current.createSendTransport({
			id: transportInfo.id,
			iceParameters: transportInfo.iceParameters,
			iceCandidates: transportInfo.iceCandidates,
			dtlsParameters: transportInfo.dtlsParameters,
		})

		// [5] DTLS ì—°ê²° ì™„ë£Œ ì‹œ ì„œë²„ì— ì—°ê²° ìš”ì²­
		newSendTransport.on('connect', ({ dtlsParameters }, callback) => {
			socket.emit('call_connectTransport', { dtlsParameters, type: 'send' })
			callback()
		})

		// [6] produce ì´ë²¤íŠ¸ ë°œìƒ ì‹œ ì„œë²„ì— ìŒì„± producer ìƒì„± ìš”ì²­
		newSendTransport.on(
			'produce',
			async ({ kind, rtpParameters }, callback) => {
				socket.emit(
					'call_produce',
					{ kind, rtpParameters, callId },
					({ id }) => {
						callback({ id })
					}
				)
			}
		)

		// [7] ì‚¬ìš©ìì˜ ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ track ê°€ì ¸ì˜¤ê¸°
		const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
		const track = stream.getAudioTracks()[0]

		// [8] ì˜¤ë””ì˜¤ íŠ¸ë™ì„ sendTransportì— ì—°ê²°í•˜ì—¬ ì „ì†¡ ì‹œì‘
		const newVoiceProducer = await newSendTransport.produce({ track })

		if (isMicOn) {
			await newVoiceProducer.resume()
		} else {
			await newVoiceProducer.pause()
		}

		// [9] ì„œë²„ì— ìˆ˜ì‹ ìš© transportë„ ë³„ë„ë¡œ ìš”ì²­
		const recvTransportInfo = await new Promise<
			| VoiceTransportOptions
			| {
					error: string
			  }
		>((resolve) => {
			socket.emit('call_createTransport', 'recv', (res) => resolve(res))
		})

		if ('error' in recvTransportInfo) {
			console.error('âŒ Transport ìƒì„± ì‹¤íŒ¨:', recvTransportInfo.error)
			return
		}

		// [10] í´ë¼ì´ì–¸íŠ¸ ì¸¡ recvTransport ìƒì„±
		const newRecvTransport: mediasoupClient.types.Transport =
			deviceRef.current.createRecvTransport({
				id: recvTransportInfo.id,
				iceParameters: recvTransportInfo.iceParameters,
				iceCandidates: recvTransportInfo.iceCandidates,
				dtlsParameters: recvTransportInfo.dtlsParameters,
			})

		// [11] ìˆ˜ì‹ ìš© transport ì—°ê²° ì‹œ ì„œë²„ì— ì•Œë¦¼
		newRecvTransport.on('connect', ({ dtlsParameters }, callback) => {
			socket.emit('call_connectTransport', { dtlsParameters, type: 'recv' })
			callback()
		})

		// [12] ìƒëŒ€ë°©ì´ ìƒˆë¡œìš´ producerë¥¼ ìƒì„±í–ˆì„ ë•Œ ìˆ˜ì‹  ì²˜ë¦¬
		socket.off('call_newProducer')
		socket.on('call_newProducer', ({ producerId, kind }) => {
			// [13] ì„œë²„ì— í•´ë‹¹ producerë¥¼ consume ìš”ì²­
			if (!deviceRef.current || !deviceRef.current.loaded) return
			socket.emit(
				'call_consume',
				{
					producerId,
					callId,
					kind,
					rtpCapabilities: deviceRef.current.rtpCapabilities,
				},
				async (consumerParams) => {
					// [14] consumer ê°ì²´ ìƒì„±
					if ('error' in consumerParams) {
						console.error('ì˜¤ë””ì˜¤ ìˆ˜ì‹  ì‹¤íŒ¨:', consumerParams.error)
						return
					}
					const consumer = await newRecvTransport.consume({
						id: consumerParams.id,
						producerId: consumerParams.producerId,
						kind: consumerParams.kind,
						rtpParameters: consumerParams.rtpParameters,
					})

					await consumer.resume()
					consumersRef.current.push(consumer)

					// [15] ìŠ¤íŠ¸ë¦¼ì— íŠ¸ë™ ì—°ê²°
					const newLocalStream = new MediaStream()
					newLocalStream.addTrack(consumer.track)

					if (consumer.kind === 'video') {
						const video = document.createElement('video')
						video.srcObject = newLocalStream
						video.autoplay = true
						video.playsInline = true
						video.controls = true
						// ì—¬ê¸° ë°”ê¿”
						document.getElementById('videoContainer')?.appendChild(video)

						videoElementsRef.current.push(video)
					} else if (consumer.kind === 'audio') {
						const audio = document.createElement('audio')
						audio.srcObject = newLocalStream
						audio.autoplay = true
						audio.controls = true
						audio.hidden = true
						// ì—¬ê¸° ë°”ê¿”
						document.body.appendChild(audio)
						audioElementsRef.current.push(audio)
					}

					setLocalStream(newLocalStream)
				}
			)
		})

		socket.on('call_peerLeft', (peer) => {})

		setSendTransport(newSendTransport)
		setRecvTransport(newRecvTransport)
		setVoiceProducer(newVoiceProducer)
		setCallId(callId)
	}

	function stopCalling() {
		console.log('ğŸ”´ í†µí™” ì¢…ë£Œ ì‹œì‘')

		try {
			sendTransport?.close()
			recvTransport?.close()
			voiceProducer?.close()
			consumersRef.current.forEach((c) => c.close())
			audioElementsRef.current.forEach((el) => {
				el.pause()
				el.srcObject = null
				el.remove()
			})
			videoElementsRef.current.forEach((el) => {
				el.pause()
				el.srcObject = null
				el.remove()
			})

			// ë¦¬ì…‹
			setSendTransport(null)
			setRecvTransport(null)
			setVoiceProducer(null)
			setCameraProducer(null)
			setScreenProducer(null)
			consumersRef.current.length = 0
			audioElementsRef.current.length = 0

			socket.off('call_newProducer') // í•¸ë“¤ëŸ¬ê°€ í•¨ìˆ˜í˜•ì´ë¼ ì œê±° ê°€ëŠ¥
			console.log('âœ… í†µí™” ì¢…ë£Œ ì™„ë£Œ')
			if (localStream) {
				localStream.getTracks().forEach((t) => t.stop())
				setLocalStream(null)
			}
		} catch (e) {
			console.error('í†µí™” ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜', e)
		}
	}

	async function getJoinList() {
		if (callId) {
			const profiles = await new Promise<PeerState[] | { error: string }>(
				(resolve) =>
					socket.emit('call_getPeerStates', callId, (peers) => resolve(peers))
			)

			if ('error' in profiles) {
				return []
			}

			return profiles
		}

		return []
	}

	if (callType === 'only-voice') {
		return {
			startCalling,
			stopCalling,
			getJoinList,
			toggleMic,
			isMicOn,
		}
	} else if (callType === 'only-camera') {
		return {
			startCalling,
			stopCalling,
			getJoinList,
			toggleCamera,
			isCameraOn,
		}
	} else if (callType === 'only-screen') {
		return {
			startCalling,
			stopCalling,
			getJoinList,
			toggleScreen,
			isScreenOn,
		}
	} else {
		return {
			startCalling,
			stopCalling,
			getJoinList,
			toggleMic,
			isMicOn,
			toggleCamera,
			isCameraOn,
			toggleScreen,
			isScreenOn,
		}
	}
}
